{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Module9_RandomForest.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPQAxo1ymB4GGW5UlIxEJxy"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"J9GyaufTuK6F"},"source":["#**Module 9: Random Forest Classification**\n","\n","In this notebook, we are going to set up a Random Forest model in Python. At the end of this module, you will be able to:\n","\n","* Explain what Random Forest does\n","* Build and evaluate a Random Forest\n","\n","**Be sure to expand all the hidden cells, run all the code, and do all the exercises--you will need the techniques for the lesson lab!**\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Ypv23z_l-Vx7"},"source":["#**What is Random Forest?**\n","For the previous module on simple tree construction, there's a chance that each of you have slightly different numeric results. Why? Because the sampling to produce the training and test sets is random. So, while performing the train_test_split, each student built the model based on a somewhat different training set. This means that each student's model is also slightly different from that of her peers. \n","\n","So, whose results are the actual, real results, then?\n","\n","The answer is: We really can't tell. Each tree that each student built has some validity, and we can have some confidence in its final predictions. \n","\n","But wouldn't it be great if we could have more confidence and come to a better overall result for the entire class? That's what the popular Random Forest algorithm does.\n","\n","Random Forest doesn't build just one tree--it builds an entire classroom full of trees, each one of which is based on a slightly different training set (which is, in fact, a small randomized subset of the big overall training set). To save processing power, Random Forest then picks just a random few of the attributes to consider when building each tree, so that no two trees are based on the same attributes. Finally, Random Forest evaluates all the trees it has constructed and, for a given prediction, outputs the class assignment that is the mode of the classes (classification) or, if you run it as a regression tree, the mean prediction (regression) of the individual trees.\n","\n","<div>\n","<img src=\"https://raw.githubusercontent.com/shstreuber/Data-Mining/master/images/randomforest2.png\" width=\"600\">\n","</div>\n","\n","So, we have:\n","* A number of trees\n","* Using a random subset of features in the dataset to make their split decisions\n","* Built on a number of slightly different training subsets, selected as random samples with replacement (= bootstrap aggregating or bagging) from the overall training set\n","* A voting function that selects the mode of the classes (classification or the mean prediction (regression)\n","\n","In other words, we introduce dual randomness into our classification in order to pick the best model from the places where all the individual trees overlap. That leaves us with much greater accuracy for our model.\n","\n","We are working with the [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) from the scikit-learn package.\n"]},{"cell_type":"markdown","metadata":{"id":"L8t8Ncq1E8NB"},"source":["#**0. Preparation and Setup**\n","As before, we are following the basic classification steps:\n","\n","1. Exploratory Data Analysis to see how the data is distributed and to determine what the class attribute in the dataset should be. This will be the attribute you'll predict later on\n","2. Preprocess the data (remove n/a, transform data types as needed, deal with missing data) and ensure that the dependent attribute is CATEGORICAL\n","3. Split the data into a training set and a test set\n","4. Build the model based on the training set\n","5. Test the model on the test set \n","6. Determine the quality of the model with the help of a Confusion Matrix and a Classification Report.\n","\n","As with our previous problems, we will use the insurance dataset again."]},{"cell_type":"code","metadata":{"id":"FkfMtiHGwLo0","colab":{"base_uri":"https://localhost:8080/","height":257},"executionInfo":{"status":"ok","timestamp":1624808058292,"user_tz":300,"elapsed":1933,"user":{"displayName":"Sonja Streuber","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQD93L4k89S61xRuTv6_J_-STpROkvxgQny5nHWQ=s64","userId":"07600325844086946297"}},"outputId":"d6af7590-d135-4e12-9f6d-f0a317345bb7"},"source":["import numpy as np\n","import pandas as pd \n","import matplotlib.pyplot as plt\n","from scipy import spatial\n","import statsmodels.api as sm\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","np.random.seed(42)\n","\n","from IPython.display import HTML # This is just for me so I can embed videos\n","from IPython.display import Image # This is just for me so I can embed images\n","\n","#Reading in the data as insurance dataframe\n","insurance = pd.read_csv(\"https://raw.githubusercontent.com/shstreuber/Data-Mining/master/data/insurance_with_categories.csv\")\n","\n","#Verifying that we can see the data\n","insurance.head()"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>sex</th>\n","      <th>bmi</th>\n","      <th>children</th>\n","      <th>smoker</th>\n","      <th>region</th>\n","      <th>charges</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>19</td>\n","      <td>female</td>\n","      <td>27.900</td>\n","      <td>0</td>\n","      <td>yes</td>\n","      <td>southwest</td>\n","      <td>16884.92400</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>18</td>\n","      <td>male</td>\n","      <td>33.770</td>\n","      <td>1</td>\n","      <td>no</td>\n","      <td>southeast</td>\n","      <td>1725.55230</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>28</td>\n","      <td>male</td>\n","      <td>33.000</td>\n","      <td>3</td>\n","      <td>no</td>\n","      <td>southeast</td>\n","      <td>4449.46200</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>33</td>\n","      <td>male</td>\n","      <td>22.705</td>\n","      <td>0</td>\n","      <td>no</td>\n","      <td>northwest</td>\n","      <td>21984.47061</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>32</td>\n","      <td>male</td>\n","      <td>28.880</td>\n","      <td>0</td>\n","      <td>no</td>\n","      <td>northwest</td>\n","      <td>3866.85520</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   age     sex     bmi  children smoker     region      charges\n","0   19  female  27.900         0    yes  southwest  16884.92400\n","1   18    male  33.770         1     no  southeast   1725.55230\n","2   28    male  33.000         3     no  southeast   4449.46200\n","3   33    male  22.705         0     no  northwest  21984.47061\n","4   32    male  28.880         0     no  northwest   3866.85520"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"iIgPPPy1HHof"},"source":["#**1. Exploratory Data Analysis (EDA)**\n","As before, we have the option to either do this in a code cell, or to import the HTML-based pandas_profile package. \n","\n","Test your EDA skills below:"]},{"cell_type":"code","metadata":{"id":"ryy4rOG4Hpli"},"source":["# Build a data summary for ALL data in the set (not just numeric!)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QBvEnb0UHyFW"},"source":["# Build a histogram for the numeric values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qxHMM_OAH2TL"},"source":["# Build a pie chart for number of children!"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"--Jl3_R3IGjl"},"source":["#**2. Preprocessing: Building the Analysis Set**\n","You have done this before. Build an insurance_rf dataset consisting of age, bmi, children, charges, and--again--region as the class attribute."]},{"cell_type":"code","metadata":{"id":"x7StpkwSIjwk"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6eHI3YdExeDt"},"source":["# **3. Building the Training and Test Datasets**\n","As before, we cannot do classification without training and test data. You did this previously. Do it again--we want 20% of the data set as test and 80% as training set."]},{"cell_type":"code","metadata":{"id":"Ht6bs3-3xrIN"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GdH99xuwyoK-"},"source":["# **4. Building and Training the Classifier**\n","We are going to use the [RandomForestClassifier from sklearn.ensemble](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html). The RandomForestClassifier has a number of really interesting parameters that we can control in order to optimize our model to run quickly and efficiently, especially the sub-sample size, which is controlled with the max_samples parameter if bootstrap=True (default), otherwise the whole dataset is used to build each tree."]},{"cell_type":"markdown","metadata":{"id":"5DrXRCY0Kpfb"},"source":["##**4.1 Building the Classifier**\n","\n","The most important parameters are:\n","* n_estimators int, default=100 --\n","The number of trees in the forest.\n","* criterion{“gini”, “entropy”}, default=”gini” -- \n","The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “entropy” for the information gain. Note: this parameter is tree-specific.\n","* max_features{“auto”, “sqrt”, “log2”}, int or float, default=”auto” -- \n","The number of features to consider when looking for the best split: If int, then consider max_features features at each split. If “auto”, then max_features=sqrt(n_features). If “log2”, then max_features=log2(n_features).\n","If None, then max_features=n_features.\n","* max_depthint, default=None -- \n","The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n","* min_samples_split int or float, default=2\n","The minimum number of samples required to split an internal node\n","* bootstrap bool, default=True -- Whether bootstrap samples are used when building trees (which is 50% of the whole idea behind Random Forest). If False, the whole dataset is used to build each tree.\n","\n","Let's get started!"]},{"cell_type":"code","metadata":{"id":"cZPJawY-ykUv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624809314203,"user_tz":300,"elapsed":344,"user":{"displayName":"Sonja Streuber","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQD93L4k89S61xRuTv6_J_-STpROkvxgQny5nHWQ=s64","userId":"07600325844086946297"}},"outputId":"59fa5a8a-991e-4521-faef-b62168b76451"},"source":["# Configuring the classifier and using get_params to double-check all the parameters with which it is configured\n","\n","rf = RandomForestClassifier()\n","rf.get_params"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<bound method BaseEstimator.get_params of RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n","                       criterion='gini', max_depth=None, max_features='auto',\n","                       max_leaf_nodes=None, max_samples=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, n_estimators=100,\n","                       n_jobs=None, oob_score=False, random_state=None,\n","                       verbose=0, warm_start=False)>"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"O__ilTPrKzHw"},"source":["##**4.2 Training the Classifier**\n","Just like before, we are using .fit() to train our classifier! Remember that we named it rf. You'll want your training data inside the parentheses.\n","\n","Give it a shot below!"]},{"cell_type":"code","metadata":{"id":"pXyCMXBzLLBL"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"geS3TgBALL9z"},"source":["Just incase you're lost: The solutions are posted at the end of this workbook."]},{"cell_type":"markdown","metadata":{"id":"43eGwtTNQGuQ"},"source":["# **5. Use the Classifier to test and predict**\n","There is nothing different about the steps below than what you have already done. Uncomment the second line starting with \"print\" if you would like to see the output of your predictions."]},{"cell_type":"code","metadata":{"id":"17nL0-SYQBmC"},"source":["y_pred = rf.predict(X_test)\n","# print(y_pred) # If you want to see the big long list, uncomment this line!"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XWfQmlvBQoq_"},"source":["# **6. Evaluate the Quality of the Model**\n","Again, we will look at the following:\n","1. Accuracy score\n","2. Confusion matrix\n","3. Classification Report\n","\n","The interesting part will be to see if any of the predictions have improved from the simple tree model in the previous module."]},{"cell_type":"code","metadata":{"id":"h73LaKzLQzMR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624809786438,"user_tz":300,"elapsed":219,"user":{"displayName":"Sonja Streuber","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQD93L4k89S61xRuTv6_J_-STpROkvxgQny5nHWQ=s64","userId":"07600325844086946297"}},"outputId":"c0412bf1-11b0-4482-b9fe-7ecf7293df46"},"source":["# First, the accuracy score\n","accuracy_score(y_test, y_pred)"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.3656716417910448"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"jrLQHFFHNtPT"},"source":["What was the accuracy score for the simple tree? Did using Random Forest improve it? Record your observations below."]},{"cell_type":"markdown","metadata":{"id":"4gdah7AcN0x6"},"source":[""]},{"cell_type":"code","metadata":{"id":"PjkZplnfRHrP","colab":{"base_uri":"https://localhost:8080/","height":301},"executionInfo":{"status":"ok","timestamp":1624810050099,"user_tz":300,"elapsed":534,"user":{"displayName":"Sonja Streuber","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQD93L4k89S61xRuTv6_J_-STpROkvxgQny5nHWQ=s64","userId":"07600325844086946297"}},"outputId":"050dbfaf-1100-455b-c451-34d3132005ed"},"source":["# Next, the Confusion Matrix\n","from sklearn.metrics import plot_confusion_matrix\n","plot_confusion_matrix(rf, X_test, y_test)"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f729bbb6a90>"]},"metadata":{"tags":[]},"execution_count":9},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"h5VWCR5hOpAk"},"source":["What did the Confusion Matrix look like for the simple tree? What differences do you notice? Record your observations in the field below."]},{"cell_type":"markdown","metadata":{"id":"_T8LhaHYO0my"},"source":[""]},{"cell_type":"code","metadata":{"id":"61_SAbqjRosa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624810387724,"user_tz":300,"elapsed":216,"user":{"displayName":"Sonja Streuber","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQD93L4k89S61xRuTv6_J_-STpROkvxgQny5nHWQ=s64","userId":"07600325844086946297"}},"outputId":"61564066-3834-4748-9793-df9d2fce35ec"},"source":["# Finally, the Classification Report\n","import sklearn.metrics as metrics\n","from sklearn.metrics import classification_report\n","\n","print(metrics.classification_report(y_test, y_pred, labels=['southwest', 'southeast', 'northwest', 'northeast']))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","   southwest       0.37      0.38      0.37        61\n","   southeast       0.49      0.43      0.46        81\n","   northwest       0.28      0.29      0.29        69\n","   northeast       0.32      0.35      0.33        57\n","\n","    accuracy                           0.37       268\n","   macro avg       0.36      0.36      0.36       268\n","weighted avg       0.37      0.37      0.37       268\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XYp9xLc8PzQg"},"source":["Again, compare this output with the output for the simple tree. What are the differences? Overall, would you say that Random Forest works better? Or, given that we're doing a whole lot more processing, is any improvement worth it? Record your answer below."]},{"cell_type":"markdown","metadata":{"id":"-AgmJvrhQMhL"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"cJvlXK59SCzn"},"source":["# **What If ...**\n","So far, we have used only the default settings on the Random Forest algorithm. What if we play with different configuration settings, such as the number of trees? Or the depth of the trees? Or the minimum samples required to split?"]},{"cell_type":"markdown","metadata":{"id":"cLWRE7YTQ2g8"},"source":["First, let's set up the parameters as variables so that we can easily change them:"]},{"cell_type":"code","metadata":{"id":"yHWW2X3PSXpk","executionInfo":{"status":"ok","timestamp":1624811078856,"user_tz":300,"elapsed":217,"user":{"displayName":"Sonja Streuber","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQD93L4k89S61xRuTv6_J_-STpROkvxgQny5nHWQ=s64","userId":"07600325844086946297"}}},"source":["# We are setting up the n_estimators and other configuration parameters so that we can easily change them\n","# Feel free to comment any of these out or change the values and re-run the cells below to see how this changes the result\n","n_estimators = 1000 # This is the number of different trees to build; default was 100; we are increasing this number tenfold.\n","min_samples_split = 5 # Previously, we ran this with the default split of 2\n","criterion='entropy' # This is for Information Gain; previously, we ran this with the Gini Index"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zX24q5UgRBtF"},"source":["Then, let's build the classifier again, now with the different settings."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lPzlGhOxRHGc","executionInfo":{"status":"ok","timestamp":1624811087005,"user_tz":300,"elapsed":5167,"user":{"displayName":"Sonja Streuber","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQD93L4k89S61xRuTv6_J_-STpROkvxgQny5nHWQ=s64","userId":"07600325844086946297"}},"outputId":"796a8409-051b-4c58-e044-720935a52a84"},"source":["rf2 = RandomForestClassifier(verbose=1, n_estimators=n_estimators, min_samples_split=min_samples_split, criterion=criterion)\n","rf2.fit(X_train, y_train)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    4.7s finished\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n","                       criterion='entropy', max_depth=None, max_features='auto',\n","                       max_leaf_nodes=None, max_samples=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=5,\n","                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n","                       n_jobs=None, oob_score=False, random_state=None,\n","                       verbose=1, warm_start=False)"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"xOkCsPkSS3QZ"},"source":["Time to predict and evaluate with accuracy score, Confusion Matrix, and Classification Report!"]},{"cell_type":"code","metadata":{"id":"a3IlVkRHT8y8"},"source":["# Testing and predicting\n","y_pred = rf2.predict(X_test)\n","\n","print(accuracy_score(y_test, y_pred))\n","plot_confusion_matrix(rf2, X_test, y_test)\n","print(metrics.classification_report(y_test, y_pred, labels=['southwest', 'southeast', 'northwest', 'northeast']))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IoLq379zTCpg"},"source":["##Your Turn\n","Try this with a number of different settings. Does using 1,000 trees improve the accuracy by a little--or a lot? What about 10,000 trees? \n","\n","Play around with the settings, then record below what you have done and what your results were. Interpret what you're seeing: Is more processing worth it? Or is there a point where we accept the results as \"good enough\"?"]},{"cell_type":"markdown","metadata":{"id":"3pS-kgQ8TgvS"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"WIDox2nGTiPY"},"source":["#**Towards Optimization**\n","You just played with the tree setting manually. What if we could cycle the algorithm through a list of \"number of trees\" settings and see what happens then?\n","\n","All we need is a quick \"for\" loop with a range. This range setting is configured like this:\n","\n","\n","```\n","range(starting_point, termination_point, increment_size)\n","```\n","In other words range(20,200,20) means that we start with 20 trees and go up to 200 in steps of 20. So, we will look at the behavior for 20, 40, 60, 80, 100, 120, 140, 160, 180, and 200 trees. The code is below.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"d4ATX_CUVMxt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624811702895,"user_tz":300,"elapsed":3624,"user":{"displayName":"Sonja Streuber","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQD93L4k89S61xRuTv6_J_-STpROkvxgQny5nHWQ=s64","userId":"07600325844086946297"}},"outputId":"8e04e118-2910-494f-f845-b0151c27b255"},"source":["# We can even cycle through a number of trees in the Random Forest\n","for n_estimators in range(20,200,20):\n","    print('Accuracy score using n_estimators =', n_estimators, end = ': ')\n","         \n","    rf3 = RandomForestClassifier(n_estimators = n_estimators, verbose=1)\n","    rf3.fit(X_train, y_train)\n","    y_pred = rf3.predict(X_test)\n","    print(accuracy_score(y_test, y_pred))"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Accuracy score using n_estimators = 20: 0.3805970149253731\n","Accuracy score using n_estimators = 40: "],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.1s finished\n","[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n","[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:    0.1s finished\n","[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:    0.0s finished\n","[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"],"name":"stderr"},{"output_type":"stream","text":["0.3694029850746269\n","Accuracy score using n_estimators = 60: "],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    0.2s finished\n","[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    0.0s finished\n","[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"],"name":"stderr"},{"output_type":"stream","text":["0.3582089552238806\n","Accuracy score using n_estimators = 80: "],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    0.2s finished\n","[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    0.0s finished\n","[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"],"name":"stderr"},{"output_type":"stream","text":["0.3694029850746269\n","Accuracy score using n_estimators = 100: "],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.3s finished\n","[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n","[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"],"name":"stderr"},{"output_type":"stream","text":["0.3619402985074627\n","Accuracy score using n_estimators = 120: "],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:    0.3s finished\n","[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:    0.0s finished\n","[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"],"name":"stderr"},{"output_type":"stream","text":["0.376865671641791\n","Accuracy score using n_estimators = 140: "],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=1)]: Done 140 out of 140 | elapsed:    0.4s finished\n","[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done 140 out of 140 | elapsed:    0.0s finished\n","[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"],"name":"stderr"},{"output_type":"stream","text":["0.3656716417910448\n","Accuracy score using n_estimators = 160: "],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed:    0.4s finished\n","[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed:    0.0s finished\n","[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"],"name":"stderr"},{"output_type":"stream","text":["0.3694029850746269\n","Accuracy score using n_estimators = 180: 0.373134328358209\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=1)]: Done 180 out of 180 | elapsed:    0.5s finished\n","[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done 180 out of 180 | elapsed:    0.0s finished\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"wYUPerq3WLg7"},"source":["How about setting this to 1,000 or even 10,000 trees and seeing the accuracy score change? Go ahead and play with the range setting! Then record below which range setting you think works best for you."]},{"cell_type":"markdown","metadata":{"id":"l2JHVonXVE6L"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"5wFvxdHwIm-h"},"source":["#Solutions (to help you if you get stuck)"]},{"cell_type":"code","metadata":{"id":"NcGZVdvaItQ2"},"source":["# This is the solution for task 2 above. \n","insurance_rf = pd.DataFrame(insurance, columns = ['age', 'bmi', 'children','charges','region'])\n","insurance_rf.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bBZX_ZvfJYRo"},"source":["# This is the solution for task 3 above:\n","from sklearn.model_selection import train_test_split\n","x=insurance_rf.iloc[:,:4] # all parameters\n","y=insurance_rf['region'] # class labels 'southwest', 'southeast', 'northwest', 'northeast'\n","X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2) \n","print(\"X_train shape: {}\".format(X_train.shape))\n","print(\"X_test shape: {}\".format(X_test.shape))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ut7PtU_dOPPO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624809320338,"user_tz":300,"elapsed":529,"user":{"displayName":"Sonja Streuber","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQD93L4k89S61xRuTv6_J_-STpROkvxgQny5nHWQ=s64","userId":"07600325844086946297"}},"outputId":"03b643e7-aa29-4857-897e-6428eca20afa"},"source":["# Solution for task 4.2\n","rf.fit(X_train, y_train)"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n","                       criterion='gini', max_depth=None, max_features='auto',\n","                       max_leaf_nodes=None, max_samples=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, n_estimators=100,\n","                       n_jobs=None, oob_score=False, random_state=None,\n","                       verbose=0, warm_start=False)"]},"metadata":{"tags":[]},"execution_count":6}]}]}